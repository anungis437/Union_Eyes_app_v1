# Union Eyes AI: 90% Completion Implementation Plan

**Target:** Advance from 35% to 90% AI maturity by Q3 2026  
**Timeline:** January 2026 - September 2026 (9 months)  
**Owner:** Chief Technology Officer  
**Created:** December 13, 2025  
**Status:** Draft - Pending Executive Board Approval

---

## Executive Summary

### Current State (December 2025)

Union Eyes has achieved **35% overall AI maturity** with strong technology foundation:

- **Technology Infrastructure:** 90% complete (Azure OpenAI deployed, orchestrator built)
- **Core AI Features:** 60% complete (5 of 15 use cases operational since Nov 2025)
- **AI Governance:** 10% complete (policies drafted, committee not formed)
- **Training & Adoption:** 20% complete (50 stewards trained, 18% adoption)
- **Advanced Features:** 0% complete (all planned for 2026)

### Target State (September 2026)

Achieve **90% AI maturity** across all categories:

- **Technology Infrastructure:** 95% (optimization, scaling, security)
- **Core AI Features:** 90% (all 6 initial use cases enhanced)
- **Advanced Features:** 70% (7 additional use cases deployed)
- **AI Governance:** 95% (committee operational, policies approved, audits conducted)
- **Training & Adoption:** 85% (200+ stewards trained, 60% adoption)

### Gap Analysis

**55 percentage points** needed across 9 months:

- **Governance:** +85 points (10% → 95%)
- **Advanced Features:** +70 points (0% → 70%)
- **Training & Adoption:** +65 points (20% → 85%)
- **Core Features:** +30 points (60% → 90%)
- **Infrastructure:** +5 points (90% → 95%)

### Success Criteria at 90%

✅ **Governance:** Committee formed, 4+ policies approved, 2+ fairness audits completed  
✅ **Technology:** 10-12 use cases deployed, 95%+ uptime, <5% model drift  
✅ **Adoption:** 60%+ steward adoption, 200+ trained, NPS ≥55  
✅ **Business Impact:** Positive ROI, <35 day avg resolution, +40% productivity  
✅ **Responsible AI:** Zero discrimination/privacy/security incidents, 100% explainability

### Investment Required

- **Budget:** $535K over 9 months (detailed breakdown below)
- **Staffing:** Close 3.2 FTE gap (hire ML Engineer, Data Scientist, expand support roles)
- **Time:** Executive sponsor commitment (CTO 50%, Committee 10 hours/month)

### Timeline

- **Q1 2026 (Jan-Mar):** Foundation → 50% target
- **Q2 2026 (Apr-Jun):** Expansion → 70% target
- **Q3 2026 (Jul-Sep):** Maturation → 90% target

---

## 1. Category-by-Category Implementation Plans

### 1.1 AI Governance (10% → 95% = +85 points)

**Current State:**

- Policies drafted but not approved
- No AI Governance Committee formed
- No fairness audits conducted
- Limited accountability mechanisms

**Target State at 90%:**

- 7-member AI Governance Committee operational
- 4+ policies formally approved
- 2+ fairness audits completed (Q2, Q3)
- Clear decision-making authority
- Monthly committee meetings

#### Implementation Tasks

**Phase 1: Committee Formation (Jan 2026)**

| Task | Owner | Timeline | Dependencies | Success Metric |
|------|-------|----------|--------------|----------------|
| Recruit 7 committee members | Executive Board | Jan 1-10 | None | 7 members confirmed |
| Appoint Chair & Vice-Chair | President | Jan 10 | Members recruited | Chair appointed |
| Schedule kickoff meeting | Committee Chair | Jan 12 | Members recruited | Meeting scheduled |
| Committee charter adoption | Committee | Jan 15 | Kickoff held | Charter approved |
| Establish meeting cadence | Chair | Jan 15 | Charter adopted | Monthly meetings |

**Deliverable:** Operational AI Governance Committee by Jan 15, 2026

**Phase 2: Policy Approvals (Feb 2026)**

| Task | Owner | Timeline | Dependencies | Success Metric |
|------|-------|----------|--------------|----------------|
| Present AI Ethics Policy | CTO | Feb Committee Mtg | Committee formed | Policy reviewed |
| Present Responsible AI Policy | CTO | Feb Committee Mtg | Committee formed | Policy reviewed |
| Member feedback period | Communications | Feb 10-20 | Policies presented | Feedback collected |
| Policy revisions | CTO | Feb 21-25 | Feedback received | Revisions complete |
| Committee vote - Ethics | Committee | Feb 28 | Revisions done | Policy approved |
| Committee vote - Responsible AI | Committee | Feb 28 | Revisions done | Policy approved |

**Deliverable:** 2 policies approved by Feb 28, 2026

**Phase 3: Additional Policy Approvals (Mar 2026)**

| Task | Owner | Timeline | Dependencies | Success Metric |
|------|-------|----------|--------------|----------------|
| Present Fairness Framework | CTO | Mar Committee Mtg | 2 policies approved | Framework reviewed |
| Present Incident Playbook | CTO | Mar Committee Mtg | 2 policies approved | Playbook reviewed |
| Committee vote - Fairness | Committee | Mar 31 | Review complete | Framework approved |
| Committee vote - Incidents | Committee | Mar 31 | Review complete | Playbook approved |

**Deliverable:** 4 policies approved by Mar 31, 2026

**Phase 4: First Fairness Audit (Apr-May 2026)**

| Task | Owner | Timeline | Dependencies | Success Metric |
|------|-------|----------|--------------|----------------|
| Select auditor (internal or external) | CTO | Apr 1-7 | Fairness policy approved | Auditor selected |
| Audit planning | Data Science Lead | Apr 8-14 | Auditor selected | Audit plan approved |
| Data collection & analysis | Data Science team | Apr 15-28 | Plan approved | Data collected |
| Root cause analysis | Auditor | Apr 29-May 5 | Data analyzed | Root causes identified |
| Remediation recommendations | Auditor | May 6-12 | RCA complete | Recommendations ready |
| Audit report to Committee | Auditor | May Committee Mtg | Recommendations done | Report presented |

**Deliverable:** First fairness audit complete by May 15, 2026

**Phase 5: Second Fairness Audit (Jul-Aug 2026)**

| Task | Owner | Timeline | Dependencies | Success Metric |
|------|-------|----------|--------------|----------------|
| Plan Q3 audit | Data Science Lead | Jul 1-7 | Q2 audit complete | Plan approved |
| Conduct audit | Data Science team | Jul 8-Aug 4 | Plan approved | Audit complete |
| Report to Committee | Auditor | Aug Committee Mtg | Audit complete | Report presented |

**Deliverable:** Second fairness audit complete by Aug 15, 2026

#### Governance Budget

- Committee member stipends: $10K (7 members × $1.5K/year)
- External auditor (2 audits): $40K ($20K per audit)
- Policy training (Committee): $5K
- **Total Governance Budget:** $55K

#### Governance Risks & Mitigation

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Committee recruitment delays | Medium | High | Start recruitment immediately, offer stipends |
| Policy approval delays | Medium | Medium | Member feedback period, phased approvals |
| Fairness audit fails (bias found) | Low | High | 30-day remediation buffer, pre-audit testing |
| Committee turnover | Low | Medium | Vice-Chair succession plan, term limits |

---

### 1.2 Advanced Features (0% → 70% = +70 points)

**Current State:**

- 5 use cases operational (UC-01 to UC-05)
- UC-06 deployed but needs enhancements
- UC-07 to UC-15 not started (0%)

**Target State at 90%:**

- 7 additional use cases deployed (UC-07 to UC-13, excluding UC-14 multilingual, UC-15 contract automation)
- 70% of advanced features complete

#### Use Case Deployment Roadmap

**Q1 2026: 2 Use Cases**

**UC-07: Churn Risk Predictor (Jan-Feb 2026)**

| Phase | Tasks | Timeline | Owner | Success Metric |
|-------|-------|----------|-------|----------------|
| **Design** | Define churn (definition: inactive 6+ months), identify predictors (engagement, disputes, dues) | Jan 6-12 | Product Lead | Requirements doc |
| **Data** | Collect historical data (2020-2025), label churned members | Jan 13-19 | Data Engineer | Dataset ready (10K+ members) |
| **Model** | Train classification model, validate (80%+ accuracy) | Jan 20-Feb 2 | Data Scientist | Model validated |
| **Integration** | Build API endpoint, integrate with dashboard | Feb 3-9 | ML Engineer | API functional |
| **Testing** | UAT with 10 stewards, fairness testing | Feb 10-16 | QA + Data Science | UAT passed, no bias |
| **Deployment** | Deploy to production, monitor closely | Feb 17-23 | DevOps + CTO | Deployed, alerts configured |
| **Training** | Train stewards on churn risk feature | Feb 24-28 | Training Lead | 50+ stewards trained |

**Deliverable:** UC-07 deployed by Feb 28, 2026

**UC-08: Workload Forecaster (Feb-Mar 2026)**

| Phase | Tasks | Timeline | Owner | Success Metric |
|-------|-------|----------|-------|----------------|
| **Design** | Define workload (grievances/week), identify predictors (seasonality, industry) | Feb 10-16 | Product Lead | Requirements doc |
| **Data** | Collect historical workload data (2020-2025) | Feb 17-23 | Data Engineer | Dataset ready |
| **Model** | Train time-series model (ARIMA or LSTM), validate (MAE ≤5 cases/week) | Feb 24-Mar 9 | Data Scientist | Model validated |
| **Integration** | Build API, integrate with capacity planning dashboard | Mar 10-16 | ML Engineer | API functional |
| **Testing** | UAT with regional directors, accuracy testing | Mar 17-23 | QA + Data Science | UAT passed |
| **Deployment** | Deploy to production | Mar 24-30 | DevOps + CTO | Deployed |
| **Training** | Train leadership on workload forecasting | Mar 31 | Training Lead | 20+ leaders trained |

**Deliverable:** UC-08 deployed by Mar 31, 2026

**Q2 2026: 3 Use Cases**

**UC-09: Grievance Drafting Assistant (Apr-May 2026)**

| Phase | Tasks | Timeline | Owner | Success Metric |
|-------|-------|----------|-------|----------------|
| **Design** | Define scope (suggest grievance language), identify templates | Apr 1-7 | Product Lead | Requirements doc |
| **Data** | Collect 500+ successful grievances, anonymize | Apr 8-14 | Data Engineer | Dataset ready |
| **Model** | Fine-tune GPT-4o on grievance corpus, validate (70%+ quality) | Apr 15-28 | Data Scientist | Model validated |
| **Integration** | Build drafting UI, integrate with case management | Apr 29-May 5 | ML Engineer | UI functional |
| **Testing** | UAT with 20 stewards, legal review | May 6-12 | QA + Legal | UAT passed, legal approved |
| **Deployment** | Phased rollout (20% → 100% over 2 weeks) | May 13-26 | DevOps + CTO | Deployed |
| **Training** | Train stewards on drafting assistant | May 27-31 | Training Lead | 100+ stewards trained |

**Deliverable:** UC-09 deployed by May 31, 2026

**UC-10: Negotiation Strategy Assistant (May-Jun 2026)**

| Phase | Tasks | Timeline | Owner | Success Metric |
|-------|-------|----------|-------|----------------|
| **Design** | Define scope (suggest negotiation tactics), identify strategies | May 5-11 | Product Lead | Requirements doc |
| **Data** | Collect negotiation outcomes (2020-2025), strategies used | May 12-18 | Data Engineer | Dataset ready |
| **Model** | Train recommendation model, validate (65%+ quality) | May 19-Jun 1 | Data Scientist | Model validated |
| **Integration** | Build strategy recommendation UI | Jun 2-8 | ML Engineer | UI functional |
| **Testing** | UAT with experienced negotiators | Jun 9-15 | QA + Senior Stewards | UAT passed |
| **Deployment** | Deploy to production | Jun 16-22 | DevOps + CTO | Deployed |
| **Training** | Train stewards on negotiation assistant | Jun 23-30 | Training Lead | 80+ stewards trained |

**Deliverable:** UC-10 deployed by Jun 30, 2026

**UC-11: Dues Arrears Predictor (Jun 2026)**

| Phase | Tasks | Timeline | Owner | Success Metric |
|-------|-------|----------|-------|----------------|
| **Design** | Define arrears risk, identify predictors (payment history, employment) | Jun 2-8 | Product Lead | Requirements doc |
| **Data** | Collect payment data (2020-2025), label delinquent members | Jun 9-15 | Data Engineer | Dataset ready (sensitive data) |
| **Model** | Train classification model, validate (80%+ accuracy) | Jun 16-29 | Data Scientist | Model validated |
| **Privacy** | Privacy Impact Assessment (PII involved) | Jun 23-29 | DPO | PIA approved |
| **Integration** | Build API, integrate with dues management | Jun 30-Jul 6 | ML Engineer | API functional |
| **Testing** | UAT with finance team, fairness testing (critical!) | Jul 7-13 | QA + Data Science | UAT passed, no bias |
| **Deployment** | Deploy with enhanced monitoring (fairness critical) | Jul 14-20 | DevOps + CTO | Deployed |

**Deliverable:** UC-11 deployed by Jul 20, 2026

**Q3 2026: 2 Use Cases**

**UC-12: CBA Compliance Checker (Jul-Aug 2026)**

| Phase | Tasks | Timeline | Owner | Success Metric |
|-------|-------|----------|-------|----------------|
| **Design** | Define compliance checks (overtime, seniority, discipline) | Jul 7-13 | Product Lead | Requirements doc |
| **Data** | Collect CBA texts (100+ contracts), violation cases | Jul 14-20 | Data Engineer | Dataset ready |
| **Model** | Fine-tune NLP model on CBA corpus, validate (75%+ accuracy) | Jul 21-Aug 3 | Data Scientist | Model validated |
| **Integration** | Build compliance checker UI | Aug 4-10 | ML Engineer | UI functional |
| **Testing** | UAT with labor lawyers, accuracy testing | Aug 11-17 | QA + Legal | UAT passed, legal approved |
| **Deployment** | Deploy to production | Aug 18-24 | DevOps + CTO | Deployed |
| **Training** | Train stewards on compliance checker | Aug 25-31 | Training Lead | 100+ stewards trained |

**Deliverable:** UC-12 deployed by Aug 31, 2026

**UC-13: Sentiment Analysis (Aug-Sep 2026)**

| Phase | Tasks | Timeline | Owner | Success Metric |
|-------|-------|----------|-------|----------------|
| **Design** | Define sentiment (member satisfaction, steward burnout) | Aug 4-10 | Product Lead | Requirements doc |
| **Data** | Collect messages, survey responses (2020-2025) | Aug 11-17 | Data Engineer | Dataset ready |
| **Model** | Train sentiment classifier, validate (70%+ accuracy) | Aug 18-31 | Data Scientist | Model validated |
| **Integration** | Build sentiment dashboard | Sep 1-7 | ML Engineer | Dashboard functional |
| **Testing** | UAT with leadership team | Sep 8-14 | QA + Leadership | UAT passed |
| **Deployment** | Deploy to production | Sep 15-21 | DevOps + CTO | Deployed |

**Deliverable:** UC-13 deployed by Sep 21, 2026

#### Advanced Features Budget

| Use Case | Development Cost | Testing Cost | Training Cost | Total |
|----------|------------------|--------------|---------------|-------|
| UC-07: Churn Risk | $25K | $5K | $3K | $33K |
| UC-08: Workload Forecaster | $25K | $5K | $2K | $32K |
| UC-09: Grievance Drafting | $35K | $8K | $5K | $48K |
| UC-10: Negotiation Assistant | $30K | $7K | $4K | $41K |
| UC-11: Dues Arrears | $28K | $6K (+ fairness) | $3K | $37K |
| UC-12: CBA Compliance | $32K | $7K (+ legal) | $5K | $44K |
| UC-13: Sentiment Analysis | $22K | $5K | $2K | $29K |
| **Total Advanced Features** | **$197K** | **$43K** | **$24K** | **$264K** |

#### Advanced Features Risks & Mitigation

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Use case delays (scope creep, technical challenges) | High | Medium | Parallel development, scope reduction option |
| Accuracy below target (model doesn't learn) | Medium | High | Baseline model benchmarks, fallback to simpler models |
| User rejection (drafting/negotiation assistants) | Medium | Medium | Extensive UAT, human-in-loop design, optional features |
| Fairness issues (UC-11 dues arrears) | Low | Critical | Pre-deployment fairness audit, enhanced monitoring |
| Legal concerns (grievance drafting) | Low | High | Legal review at design phase, disclaimer language |

---

### 1.3 Training & Adoption (20% → 85% = +65 points)

**Current State:**

- 50 stewards trained (out of 250+ total)
- 18% adoption rate (45 of 250 using AI features monthly)
- Limited training materials (ad-hoc demos)
- No formal certification program

**Target State at 90%:**

- 200+ stewards trained (80% of active stewards)
- 60% adoption rate (150 of 250 using AI monthly)
- Formal training program (4-hour workshop)
- Certification program
- Member education campaign

#### Implementation Tasks

**Phase 1: Training Program Development (Jan 2026)**

| Task | Owner | Timeline | Dependencies | Success Metric |
|------|-------|----------|-------|----------------|
| Develop training curriculum | Training Lead + CTO | Jan 6-19 | None | Curriculum approved |
| Create trainer guide | Training Lead | Jan 20-26 | Curriculum done | Guide complete |
| Create participant workbook | Training Lead | Jan 20-26 | Curriculum done | Workbook complete |
| Record training videos | CTO + Product | Jan 27-31 | Materials done | 5 videos recorded |
| Develop certification exam | Training Lead | Jan 27-31 | Materials done | 20-question exam |

**Deliverable:** Complete training program by Jan 31, 2026

**Phase 2: Train-the-Trainer (Feb 2026)**

| Task | Owner | Timeline | Dependencies | Success Metric |
|------|-------|----------|-------|----------------|
| Recruit 10 AI champions | Regional Directors | Feb 1-7 | Training materials ready | 10 champions recruited |
| Train-the-trainer session | CTO | Feb 10-11 | Champions recruited | 10 trainers certified |
| Pilot training (beta test) | Champions | Feb 15-20 | Trainers certified | 30 stewards trained, feedback collected |
| Revise materials | Training Lead | Feb 21-28 | Pilot complete | Materials revised |

**Deliverable:** 10 certified trainers by Feb 28, 2026

**Phase 3: Mass Training Rollout (Mar-Aug 2026)**

| Month | Target | Trainers | Sessions | Cumulative Trained |
|-------|--------|----------|----------|-------------------|
| Mar 2026 | 40 stewards | 4 trainers | 5 sessions | 90 total (50 existing + 40 new) |
| Apr 2026 | 30 stewards | 3 trainers | 4 sessions | 120 total |
| May 2026 | 30 stewards | 3 trainers | 4 sessions | 150 total |
| Jun 2026 | 20 stewards | 2 trainers | 3 sessions | 170 total |
| Jul 2026 | 15 stewards | 2 trainers | 2 sessions | 185 total |
| Aug 2026 | 15 stewards | 2 trainers | 2 sessions | 200 total ✅ |

**Deliverable:** 200 stewards trained by Aug 31, 2026

**Phase 4: Adoption Campaign (Mar-Sep 2026)**

**Tactics:**

1. **Gamification:** Leaderboard (most AI-assisted cases closed), badges, recognition
2. **Champions Program:** 10 AI champions share success stories, mentor peers
3. **Monthly Webinars:** "AI Tips & Tricks" series (30 min, every 2nd Tuesday)
4. **Success Stories:** Newsletter features (steward profiles, case studies)
5. **Mandatory Training:** Require certification for new stewards (Apr 2026+)
6. **Executive Sponsorship:** CTO + President promote AI in town halls

**Adoption Targets:**

- Mar 2026: 25% adoption (63 of 250 stewards)
- May 2026: 40% adoption (100 of 250 stewards)
- Jul 2026: 50% adoption (125 of 250 stewards)
- Sep 2026: 60% adoption (150 of 250 stewards) ✅

**Phase 5: Member Education (Apr-Aug 2026)**

| Task | Owner | Timeline | Dependencies | Success Metric |
|------|-------|----------|-------|----------------|
| Develop member FAQ (20 Q&A) | Communications | Apr 1-15 | Policies approved | FAQ published |
| Create explainer videos (3-5 min) | Communications | Apr 16-30 | FAQ done | 3 videos published |
| Design infographics | Communications | May 1-15 | Videos done | 3 infographics published |
| Town hall presentations | CTO + President | Jun-Aug | Materials ready | 5 town halls conducted |
| Newsletter series (6 issues) | Communications | Apr-Sep | FAQ done | 6 newsletters published |

**Deliverable:** Comprehensive member education campaign by Sep 30, 2026

#### Training & Adoption Budget

- Training curriculum development: $15K
- Train-the-trainer (10 champions): $8K
- Training sessions (150 new stewards × $100/session): $15K
- Certification program: $5K
- Adoption campaign (gamification, webinars): $12K
- Member education (videos, infographics): $20K
- **Total Training & Adoption Budget:** $75K

#### Training & Adoption Risks & Mitigation

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Low training attendance | Medium | High | Mandatory certification, paid training time, food/incentives |
| Low adoption despite training | High | High | Gamification, champions, executive sponsorship, make features sticky |
| Trainer burnout (10 champions) | Medium | Medium | Rotate trainers, compensation/recognition, limit sessions/month |
| Member resistance (fear of AI) | Medium | Medium | Transparency campaign, emphasize human oversight, success stories |

---

### 1.4 Core Features Enhancement (60% → 90% = +30 points)

**Current State:**

- UC-01 to UC-05 operational (basic functionality)
- UC-06 deployed but needs enhancements
- Limited real-time monitoring
- No automated retraining
- Baseline accuracy (85-88%)

**Target State at 90%:**

- All 6 core use cases enhanced (advanced features)
- Real-time monitoring dashboard operational
- Automated retraining pipelines
- Improved accuracy (88-92%)
- A/B testing framework

#### Implementation Tasks

**Phase 1: UC-06 Steward Recommender Enhancement (Jan-Feb 2026)**

| Task | Owner | Timeline | Success Metric |
|------|-------|----------|----------------|
| Add workload balancing (don't overload stewards) | Data Scientist | Jan 6-19 | Workload considered |
| Add expertise matching (steward skills → case type) | Data Scientist | Jan 20-Feb 2 | Expertise weighted |
| Add availability tracking (vacation, leave) | ML Engineer | Feb 3-16 | Availability real-time |
| Deploy enhancements | DevOps | Feb 17-23 | Deployed |

**Deliverable:** UC-06 enhanced by Feb 23, 2026

**Phase 2: Real-Time Monitoring Dashboard (Feb-Mar 2026)**

| Task | Owner | Timeline | Success Metric |
|------|-------|----------|----------------|
| Design dashboard (see AI_MONITORING_PROCEDURES.md) | Data Science Lead | Feb 10-16 | Design approved |
| Build dashboard infrastructure (Grafana/Metabase) | ML Engineer | Feb 17-Mar 2 | Infrastructure ready |
| Implement accuracy tracking | Data Scientist | Mar 3-9 | Accuracy metrics live |
| Implement fairness tracking | Data Scientist | Mar 10-16 | Fairness metrics live |
| Implement drift detection | Data Scientist | Mar 17-23 | Drift alerts functional |
| Configure alerts (Slack, PagerDuty) | DevOps | Mar 24-30 | Alerts configured |

**Deliverable:** Real-time monitoring dashboard operational by Mar 31, 2026

**Phase 3: Automated Retraining Pipelines (Apr-Jun 2026)**

| Task | Owner | Timeline | Success Metric |
|------|-------|----------|----------------|
| Define retraining triggers (drift, accuracy drop) | Data Science Lead | Apr 1-7 | Triggers defined |
| Build data pipeline (collect recent data) | Data Engineer | Apr 8-21 | Pipeline functional |
| Build training pipeline (automate model training) | ML Engineer | Apr 22-May 5 | Training automated |
| Build validation pipeline (test new model) | Data Scientist | May 6-19 | Validation automated |
| Build deployment pipeline (blue-green deploy) | DevOps | May 20-Jun 2 | Deployment automated |
| Test end-to-end (trigger → deploy) | Data Science team | Jun 3-16 | E2E test passed |
| Enable for UC-01 (pilot) | CTO | Jun 17-30 | UC-01 auto-retraining |

**Deliverable:** Automated retraining for UC-01 by Jun 30, 2026 (expand to other use cases Q3)

**Phase 4: Accuracy Improvements (May-Aug 2026)**

| Use Case | Current Accuracy | Target Accuracy | Improvement Strategy | Timeline |
|----------|------------------|-----------------|---------------------|----------|
| UC-01: Claim Outcome | 87% | 90% | Feature engineering (add case law precedents) | May-Jun |
| UC-02: Timeline | 82% (±10d MAE) | 85% (±7d MAE) | Add industry/regional factors | May-Jun |
| UC-03: Precedent Search | 85% (MRR) | 88% (MRR) | Fine-tune embeddings, re-rank | Jun-Jul |
| UC-04: NLP Query | 89% | 92% | Expand training data, few-shot learning | Jun-Jul |
| UC-05: Document Analysis | 84% | 87% | Fine-tune on union contracts | Jul-Aug |
| UC-06: Steward Recommender | 78% (acceptance) | 85% (acceptance) | Enhancements from Phase 1 | Jan-Feb (done) |

**Deliverable:** Accuracy improvements for 5 use cases by Aug 31, 2026

**Phase 5: A/B Testing Framework (Jul-Aug 2026)**

| Task | Owner | Timeline | Success Metric |
|------|-------|----------|----------------|
| Design A/B testing framework | Data Science Lead | Jul 1-7 | Design approved |
| Build traffic splitting (10% test, 90% control) | ML Engineer | Jul 8-21 | Traffic splitting functional |
| Build metrics comparison (accuracy, user satisfaction) | Data Scientist | Jul 22-Aug 4 | Metrics tracking functional |
| Test framework (pilot with UC-01 improvement) | Data Science team | Aug 5-18 | A/B test successful |
| Roll out to all use cases | DevOps | Aug 19-31 | A/B testing available |

**Deliverable:** A/B testing framework operational by Aug 31, 2026

#### Core Features Enhancement Budget

- UC-06 enhancements: $20K
- Real-time monitoring dashboard: $30K
- Automated retraining pipelines: $45K
- Accuracy improvements (6 use cases): $40K
- A/B testing framework: $25K
- **Total Core Features Enhancement Budget:** $160K

---

### 1.5 Infrastructure Optimization (90% → 95% = +5 points)

**Current State:**

- Azure OpenAI deployed (40K tokens/min production, 10K staging)
- Orchestrator service operational
- Basic monitoring (Azure Application Insights)
- No load testing, no disaster recovery

**Target State at 95%:**

- Performance optimized (response time <2 sec P95)
- Scaled for 3x growth (750 stewards, 15K members)
- Security hardened (penetration testing)
- Disaster recovery plan

#### Implementation Tasks

**Phase 1: Performance Optimization (Jan-Feb 2026)**

| Task | Owner | Timeline | Success Metric |
|------|-------|----------|----------------|
| Benchmark current performance (response time, throughput) | DevOps | Jan 6-12 | Baseline established |
| Optimize API caching (Redis) | ML Engineer | Jan 13-26 | Cache hit rate >50% |
| Optimize database queries | Data Engineer | Jan 27-Feb 9 | Query time <500ms |
| Implement request batching | ML Engineer | Feb 10-23 | Throughput +30% |

**Deliverable:** Performance optimized by Feb 23, 2026

**Phase 2: Scaling Preparation (Mar-Apr 2026)**

| Task | Owner | Timeline | Success Metric |
|------|-------|----------|----------------|
| Load testing (simulate 3x traffic) | DevOps | Mar 1-14 | Handle 1500 req/min |
| Increase Azure OpenAI quota (40K → 100K tokens/min) | CTO | Mar 15 | Quota increased |
| Horizontal scaling (add servers) | DevOps | Mar 16-30 | Auto-scaling configured |
| Database scaling (read replicas) | Data Engineer | Apr 1-14 | Replicas deployed |

**Deliverable:** Infrastructure scaled by Apr 14, 2026

**Phase 3: Security Hardening (May-Jun 2026)**

| Task | Owner | Timeline | Success Metric |
|------|-------|----------|----------------|
| Penetration testing (hire external firm) | CTO | May 1-31 | Test complete, report received |
| Remediate vulnerabilities | DevOps | Jun 1-21 | All critical/high vulnerabilities fixed |
| Security audit (SOC 2 prep) | CTO | Jun 22-30 | Audit complete |

**Deliverable:** Security hardened by Jun 30, 2026

**Phase 4: Disaster Recovery (Jul-Aug 2026)**

| Task | Owner | Timeline | Success Metric |
|------|-------|----------|----------------|
| Document disaster recovery plan | DevOps | Jul 1-14 | DR plan approved |
| Implement database backups (daily) | Data Engineer | Jul 15-21 | Backups automated |
| Implement geo-redundancy (failover region) | DevOps | Jul 22-Aug 11 | Failover tested |
| Conduct disaster recovery drill | CTO + team | Aug 12-18 | DR drill successful (RTO <4h, RPO <1h) |

**Deliverable:** Disaster recovery operational by Aug 18, 2026

#### Infrastructure Budget

- Performance optimization: $15K
- Load testing & scaling: $20K
- Penetration testing (external firm): $25K
- Security audit (SOC 2 prep): $15K
- Disaster recovery (geo-redundancy): $20K
- **Total Infrastructure Budget:** $95K

---

## 2. Resource Requirements

### 2.1 Budget Summary

| Category | Q1 2026 | Q2 2026 | Q3 2026 | Total |
|----------|---------|---------|---------|-------|
| **Governance** | $30K | $20K | $5K | $55K |
| **Advanced Features** | $65K | $130K | $69K | $264K |
| **Training & Adoption** | $25K | $30K | $20K | $75K |
| **Core Enhancements** | $50K | $70K | $40K | $160K |
| **Infrastructure** | $35K | $40K | $20K | $95K |
| **Staffing (new hires)** | $45K | $45K | $45K | $135K |
| **Vendors & Services** | $20K | $15K | $10K | $45K |
| **Contingency (10%)** | $27K | $35K | $21K | $83K |
| **TOTAL** | $297K | $385K | $230K | $912K |

**Note:** Original AI Strategy budget was $535K. This 90% plan requires additional $377K ($912K - $535K) due to accelerated timeline and increased scope. Recommend seeking additional funding or extending timeline to Q4 2026.

**Revised Budget (Reduced Scope):** If budget limited to $535K, recommend:

- Defer UC-13 Sentiment Analysis to Q4 2026 (-$29K)
- Reduce training budget (fewer in-person sessions, more online) (-$20K)
- Defer A/B testing framework to Q4 2026 (-$25K)
- Reduce contingency to 5% (-$41K)
- **Revised Total:** $837K (still over budget by $302K)

**Recommendation:** Request additional $300K from Executive Board to achieve 90% by Q3 2026, OR extend timeline to Q4 2026 with original $535K budget (reach 90% by Dec 2026 instead of Sep 2026).

### 2.2 Staffing Requirements

**Current Team:**

- Chief Technology Officer (50% AI)
- Data Science Lead (100% AI) - **Hired Nov 2025**
- ML Engineer (0% - NEED TO HIRE)
- Data Scientist (0% - NEED TO HIRE)
- Data Engineer (20% AI)
- DevOps Engineer (20% AI)
- Training Lead (10% AI)
- DPO (10% AI)

**Gap Analysis:**

- **Need:** 1.0 FTE ML Engineer (model deployment, API development)
- **Need:** 1.0 FTE Data Scientist (model development, accuracy improvements)
- **Need:** Expand Training Lead to 50% AI (was 10%) = +0.4 FTE
- **Need:** Expand DPO to 30% AI (was 10%) for governance = +0.2 FTE
- **Need:** Add AI Governance Coordinator (0.6 FTE) for committee support
- **Total Gap:** 3.2 FTE

**Hiring Plan:**

| Role | Type | Salary | Start Date | Rationale |
|------|------|--------|------------|-----------|
| **ML Engineer** | Full-time | $120K/yr | Jan 15, 2026 | Critical for use case deployments (UC-07+) |
| **Data Scientist** | Full-time | $115K/yr | Feb 1, 2026 | Needed for accuracy improvements, model dev |
| **AI Governance Coordinator** | Part-time (0.6 FTE) | $45K/yr | Feb 15, 2026 | Support committee, manage audits, policy tracking |
| **Training Lead Expansion** | Increase allocation | +$30K/yr | Jan 1, 2026 | From 10% to 50% AI focus |
| **DPO Expansion** | Increase allocation | +$15K/yr | Feb 1, 2026 | From 10% to 30% AI focus (governance) |

**Total New Staffing Cost:** $325K/year ($135K for 9 months Jan-Sep 2026, prorated)

**Hiring Risks:**

- Competitive market for ML talent (may need to increase salary offers)
- Onboarding takes 1-2 months (productivity ramp-up)
- Retention risk (ensure competitive compensation, growth opportunities)

### 2.3 Vendor & Services

| Vendor/Service | Cost | Purpose | Timeline |
|----------------|------|---------|----------|
| External Fairness Auditor | $40K | 2 fairness audits (Q2, Q3) | Apr-Aug 2026 |
| Penetration Testing Firm | $25K | Security hardening | May 2026 |
| Training Video Production | $15K | Professional videos for member education | Apr-May 2026 |
| External Legal Review | $10K | Review grievance drafting, CBA compliance | Apr-Jun 2026 |
| Azure OpenAI Quota Increase | Included | Increase from 40K to 100K tokens/min | Mar 2026 |
| SOC 2 Audit Prep | $15K | Security audit | Jun 2026 |

**Total Vendors & Services:** $120K

---

## 3. Timeline & Milestones

### 3.1 Quarterly Targets

**Q1 2026 (Jan-Mar): Foundation → 50% Maturity**

**Key Deliverables:**

- ✅ AI Governance Committee formed (Jan 15)
- ✅ 2 policies approved (Feb 28)
- ✅ 2 more policies approved (Mar 31)
- ✅ UC-07 Churn Risk deployed (Feb 28)
- ✅ UC-08 Workload Forecaster deployed (Mar 31)
- ✅ 40 stewards trained (90 total)
- ✅ Real-time monitoring dashboard operational (Mar 31)
- ✅ Adoption: 25% (63 stewards)

**Success Criteria at Q1 End (50% maturity):**

- Governance: 60% (committee formed, 4 policies approved)
- Advanced Features: 20% (2 of 7 use cases deployed)
- Training & Adoption: 40% (90 trained, 25% adoption)
- Core Features: 70% (monitoring dashboard, UC-06 enhanced)
- Infrastructure: 92% (performance optimized, scaled)

**Q2 2026 (Apr-Jun): Expansion → 70% Maturity**

**Key Deliverables:**

- ✅ First fairness audit completed (May 15)
- ✅ UC-09 Grievance Drafting deployed (May 31)
- ✅ UC-10 Negotiation Assistant deployed (Jun 30)
- ✅ UC-11 Dues Arrears deployed (Jul 20) - *extends into Q3*
- ✅ 80 stewards trained (170 total)
- ✅ Automated retraining for UC-01 (Jun 30)
- ✅ Accuracy improvements for UC-01, UC-02 (Jun 30)
- ✅ Adoption: 40% (100 stewards)

**Success Criteria at Q2 End (70% maturity):**

- Governance: 80% (4 policies approved, 1 fairness audit complete)
- Advanced Features: 50% (4.5 of 7 use cases deployed)
- Training & Adoption: 65% (170 trained, 40% adoption)
- Core Features: 80% (automated retraining, 2 accuracy improvements)
- Infrastructure: 94% (scaled, security hardened)

**Q3 2026 (Jul-Sep): Maturation → 90% Maturity**

**Key Deliverables:**

- ✅ Second fairness audit completed (Aug 15)
- ✅ UC-12 CBA Compliance deployed (Aug 31)
- ✅ UC-13 Sentiment Analysis deployed (Sep 21)
- ✅ 30 stewards trained (200 total) ✅
- ✅ Accuracy improvements for UC-03, UC-04, UC-05 (Aug 31)
- ✅ A/B testing framework operational (Aug 31)
- ✅ Disaster recovery operational (Aug 18)
- ✅ Adoption: 60% (150 stewards) ✅

**Success Criteria at Q3 End (90% maturity):**

- Governance: 95% (4 policies approved, 2 fairness audits, committee operational)
- Advanced Features: 70% (7 of 10 advanced use cases deployed)
- Training & Adoption: 85% (200 trained, 60% adoption)
- Core Features: 90% (all 6 use cases enhanced, automated retraining, accuracy improved)
- Infrastructure: 95% (scaled, secured, DR operational)

### 3.2 Critical Path

**Critical path items (delays here delay entire plan):**

1. **AI Governance Committee Formation (Jan 1-15)** → Gates policy approvals
2. **ML Engineer Hire (Jan 1-15)** → Gates all use case deployments
3. **Data Scientist Hire (Feb 1)** → Gates accuracy improvements
4. **Policy Approvals (Feb-Mar)** → Gates fairness audits
5. **First Fairness Audit (Apr-May)** → Validates fairness approach, gates second audit
6. **Real-Time Monitoring Dashboard (Mar 31)** → Gates automated retraining

**Slack/Buffer:**

- Member education campaign can slip without impacting 90% target (member-facing, not internal)
- UC-13 Sentiment Analysis can defer to Q4 if needed (lower priority)
- Some training sessions can shift between months

---

## 4. Dependencies & Risks

### 4.1 Key Dependencies

**Internal Dependencies:**

- Executive Board approval of budget (+$300K)
- Executive Board approval of new hires (ML Engineer, Data Scientist)
- Committee member recruitment (7 members)
- Steward availability for training (paid training time)
- Member feedback on policies (Feb 10-20)

**External Dependencies:**

- Azure OpenAI quota increase approval (Mar 2026)
- External auditor availability (fairness audits in Apr-May, Jul-Aug)
- Penetration testing firm availability (May 2026)
- Legal review availability (Apr-Jun for UC-09, UC-12)

**Technical Dependencies:**

- Real-time monitoring dashboard (gates automated retraining)
- Policy approvals (gate fairness audits)
- Fairness audit framework approval (gates first audit)
- Training materials (gate mass training rollout)

### 4.2 Top 10 Risks & Mitigation

| # | Risk | Probability | Impact | Mitigation Strategy |
|---|------|-------------|--------|---------------------|
| 1 | **Budget not approved (+$300K)** | Medium | Critical | Plan B: Extend timeline to Q4 2026, reduce scope (defer UC-13, A/B testing) |
| 2 | **Hiring delays (ML Engineer, Data Scientist)** | Medium | High | Start recruiting immediately, increase salary offers, use contractors short-term |
| 3 | **Committee formation delays** | Medium | High | Executive Board directly appoints members, offer stipends for service |
| 4 | **Fairness audit fails (bias detected)** | Low | High | Build in 30-day remediation buffer, pre-audit testing, conservative rollout |
| 5 | **Use case delays (UC-09, UC-10, UC-11)** | High | Medium | Parallel development, reduce scope, accept 85% instead of 90% if needed |
| 6 | **Low steward adoption (<60%)** | Medium | High | Mandatory training for new stewards, gamification, executive sponsorship, make features sticky |
| 7 | **Model accuracy below target** | Medium | Medium | Accept lower targets (83% instead of 85%), iterate, use simpler models |
| 8 | **Azure OpenAI quota not increased** | Low | Medium | Throttle non-critical requests, use alternative models (Anthropic), optimize prompts |
| 9 | **Legal concerns (UC-09 grievance drafting)** | Low | High | Involve legal early (design phase), add disclaimers, human review required |
| 10 | **Member resistance to AI** | Medium | Medium | Transparency campaign, emphasize human oversight, success stories, address concerns directly |

**Risk Monitoring:**

- Monthly risk review at AI Governance Committee meetings
- Risk register updated in [AI_RISK_MANAGEMENT.md](AI_RISK_MANAGEMENT.md)
- Escalation to Executive Board if critical risks materialize

---

## 5. Success Metrics & Tracking

### 5.1 Success Metrics at 90%

**Governance (95%):**

- ✅ 7-member AI Governance Committee formed and operational
- ✅ Monthly committee meetings (9 meetings Jan-Sep 2026)
- ✅ 4+ policies formally approved (Ethics, Responsible AI, Fairness, Incidents)
- ✅ 2+ fairness audits completed (Q2, Q3) with <3 bias issues found
- ✅ Zero major governance incidents (P1/P2 policy violations)

**Technology (90-95%):**

- ✅ 10-12 AI use cases deployed (6 core + 4-6 advanced)
- ✅ 95%+ system uptime (≤18 hours downtime over 9 months)
- ✅ <2 sec response time (P95) for all AI APIs
- ✅ <5% model drift across all production models
- ✅ Real-time monitoring dashboard operational
- ✅ Automated retraining for ≥1 use case

**Adoption (85%):**

- ✅ 200+ stewards trained (80% of active stewards)
- ✅ 60%+ steward adoption (150 of 250 using AI monthly)
- ✅ NPS ≥55 (user satisfaction)
- ✅ <20% override rate (users trust AI)
- ✅ Member education campaign complete (FAQs, videos, town halls)

**Business Impact:**

- ✅ Positive ROI (benefits > costs by Sep 2026)
- ✅ <35 day average case resolution time (from 45-60 days)
- ✅ +40% steward productivity (cases closed per steward)
- ✅ ≥88% member retention (churn reduced from 12% to <12%)

**Responsible AI:**

- ✅ Zero discrimination incidents (bias-related member complaints)
- ✅ Zero privacy breaches (PII leaks, unauthorized access)
- ✅ Zero security incidents (hacking, data theft)
- ✅ 100% explainability (all predictions include explanation)
- ✅ All high-stakes decisions have human review

### 5.2 Tracking & Reporting

**Weekly:**

- CTO reviews progress against plan
- Data Science team reviews metrics (accuracy, fairness, drift)
- Update task tracking (% complete by category)

**Monthly:**

- Present progress to AI Governance Committee
- Update overall % complete (Governance, Advanced Features, Training, Core, Infrastructure)
- Identify risks, blockers, course corrections
- Update Executive Board (written report)

**Quarterly:**

- Comprehensive review at AI Governance Committee meeting
- Fairness audit presentation
- Adjust plan based on learnings
- Public transparency report (if required by policy)

**Dashboard:**

- Real-time dashboard showing % progress toward 90%
- Accessible to: CTO, AI Committee, Executive Board

---

## 6. Conclusion

Achieving 90% AI maturity by Q3 2026 is ambitious but achievable with:

1. **Executive Board approval** of budget (+$300K) and hires (ML Engineer, Data Scientist)
2. **Rapid Committee formation** (Jan 2026) to unblock policy approvals
3. **Aggressive hiring** (Jan-Feb 2026) to enable parallel use case development
4. **Extensive training** (200 stewards by Aug 2026) to drive adoption
5. **Proactive risk management** (30-day buffers, contingency plans)

**Key Success Factors:**

- **Executive Sponsorship:** CTO + President must champion AI, remove blockers
- **Committee Commitment:** 7 members must dedicate 10 hours/month
- **Steward Buy-In:** Adoption is voluntary; must make AI features valuable and easy to use
- **Quality over Speed:** Do not compromise on fairness, accuracy, or safety to hit deadlines

**Alternative Timeline:**

- If budget limited to $535K: Extend to Q4 2026 (reach 90% by Dec 2026, not Sep 2026)
- If Committee formation delays: Add 1-2 months to timeline

**This plan balances ambition with pragmatism. Let's build AI that empowers stewards, protects members, and advances union power.**

---

**Next Steps:**

1. **Present to Executive Board (Dec 2025):** Seek approval for budget and hires
2. **Recruit Committee Members (Jan 1-10, 2026):** Identify and approach 7 candidates
3. **Post Job Openings (Jan 1, 2026):** ML Engineer, Data Scientist, AI Governance Coordinator
4. **Kickoff Meeting (Jan 15, 2026):** Launch 90% Implementation Plan

---

**Questions?**  
Contact: CTO [cto@unioneyes.org](mailto:cto@unioneyes.org)

---

**Document Control:**

- **Version:** 1.0 (Draft)
- **Status:** Pending Executive Board Approval
- **Created:** December 13, 2025
- **Owner:** Chief Technology Officer
- **Next Review:** January 2026 (post-Board approval)
