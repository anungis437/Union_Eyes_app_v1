# Union Eyes AI Ethics Policy

**Version:** 1.0 (Draft)  
**Effective Date:** February 1, 2026  
**Last Updated:** December 13, 2025  
**Owner:** AI Governance Committee  
**Review Cycle:** Annual (or as regulations change)  
**Status:** Pending AI Governance Committee Approval

---

## 1. Purpose & Scope

### Policy Purpose

This AI Ethics Policy establishes clear ethical boundaries and decision-making principles for the development, deployment, and use of artificial intelligence systems at Union Eyes. It ensures that AI technologies serve workers, strengthen unions, and uphold labor movement values.

### Who This Policy Applies To

**Required Compliance:**
- All Union Eyes employees and contractors
- Third-party vendors providing AI services
- Union staff using Union Eyes AI features
- Stewards and union members (when using AI tools)

**Governance:**
- AI Governance Committee (policy oversight)
- Union Executive Board (strategic approval)
- CTO and Data Science team (implementation)

### Policy Scope

**Covered AI Systems:**
- Predictive analytics (claim outcomes, timelines, churn)
- Natural language processing (queries, document analysis)
- Recommendation systems (steward assignment, workflow)
- Generative AI (contract drafting, member communications)
- Machine learning models (all types)

**Excluded Systems:**
- Traditional software without ML/AI components
- Simple rules-based automation
- Statistical analysis without predictive models

---

## 2. Core Ethical Principles

Union Eyes AI development and deployment is guided by **six foundational principles** (see AI_PRINCIPLES.md for detailed implementation):

### Principle 1: Validity & Reliability
AI systems must be accurate, trustworthy, and fit for purpose. Claims must be evidence-based and continuously validated.

### Principle 2: Accountability
Clear responsibility for AI decisions and outcomes. Humans make final decisions on high-stakes matters. Complete audit trails required.

### Principle 3: Fairness & Bias Detection
AI must not discriminate. Regular fairness audits mandatory. Bias incidents addressed immediately with transparency.

### Principle 4: Safety & Security
Member data and systems protected from threats. Security-first design. Incident response capabilities established.

### Principle 5: Data Privacy
Member privacy is sacred. Data minimization, consent, and member rights (access, deletion, correction) strictly enforced.

### Principle 6: Explainability & Transparency
AI decisions must be explainable in plain language. No "black box" decision-making affecting members.

---

## 3. Ethical Guidelines for AI Use

### Human-Centered AI Philosophy

**Core Commitment:** AI augments human judgment, never replaces it.

**Implementation:**
- Stewards make final decisions on grievances, settlements, member advice
- AI provides recommendations, insights, predictions
- Human oversight gates for all high-stakes decisions
- Override capability always available
- "AI suggests, humans decide" messaging

**Prohibited:** Fully automated decision-making on matters materially affecting members without human review.

### Democratic Values

**Union democracy is non-negotiable.** AI must respect and enhance democratic processes.

**Requirements:**
- Member consent for AI use (especially profiling, predictions)
- Opt-out options for non-essential AI features
- Member representation on AI Governance Committee
- Transparency reports to membership (annual minimum)
- No AI use to suppress dissent or manipulate union elections

**Prohibited:**
- AI surveillance of organizing activities without consent
- Predictive modeling of member voting behavior for manipulation
- AI-generated communications misrepresenting union positions
- Suppression of member speech or democratic participation

### Solidarity & Collective Action

**AI must strengthen, not undermine, worker solidarity.**

**Requirements:**
- AI tools available to all unions/members equitably (no "premium AI")
- Training and support provided to all users
- Data not shared across unions without explicit consent
- AI benefits shared collectively (efficiency gains = more member service)

**Prohibited:**
- Using AI to identify "troublemakers" for employer retaliation
- Profiling members for union disengagement (without intervention context)
- Creating competitive advantages for specific unions over others
- AI replacing workers without retraining/redeployment

### Worker Empowerment

**AI should empower workers, not create dependency or deskilling.**

**Requirements:**
- Training emphasizes critical thinking alongside AI tool use
- Stewards maintain core skills (legal research, case assessment)
- AI limitations clearly communicated (no overreliance)
- Regular skill assessments and refresher training

**Prohibited:**
- Allowing complete loss of traditional union skills
- Making AI tools so complex they exclude less tech-savvy users
- Creating AI dependency that leaves unions helpless if system fails

---

## 4. Prohibited AI Uses

### Absolute Prohibitions

Union Eyes will **never** develop or deploy AI for:

#### 1. Surveillance & Retaliation
- **Prohibited:** AI monitoring member social media to identify union critics
- **Prohibited:** Predictive models identifying "flight risk" members for retaliation or reduced services
- **Prohibited:** Tracking member organizing activities on behalf of employers
- **Prohibited:** Facial recognition or biometric tracking without explicit consent

#### 2. Manipulation & Deception
- **Prohibited:** AI-generated deepfakes or synthetic media impersonating real people
- **Prohibited:** Manipulative "dark patterns" in AI interfaces to coerce decisions
- **Prohibited:** AI chatbots misrepresenting themselves as human stewards
- **Prohibited:** Selective AI recommendations biased toward union's financial interests over member welfare

#### 3. Discrimination
- **Prohibited:** AI trained on biased data not corrected for fairness
- **Prohibited:** Models optimized for accuracy without fairness constraints
- **Prohibited:** Deployment of AI with known discriminatory outcomes
- **Prohibited:** Using protected attributes (race, gender, age, etc.) as direct features except when legally required (affirmative action)

#### 4. Harm to Workers
- **Prohibited:** AI used to justify layoffs or replacement of union staff/stewards
- **Prohibited:** Automated discipline or termination recommendations for union employees
- **Prohibited:** Sharing member data with employers without consent (except as legally required)
- **Prohibited:** AI optimizing employer outcomes at member expense (e.g., recommending low settlements to close cases faster)

#### 5. Violations of Rights
- **Prohibited:** AI overriding member data rights (access, deletion, correction)
- **Prohibited:** Processing member data for purposes beyond those consented to
- **Prohibited:** AI decisions affecting members without explanation capability
- **Prohibited:** Sharing member data with third parties for non-union purposes (marketing, political campaigns)

### Conditional Prohibitions (Require Special Approval)

These AI uses are **presumed prohibited** unless AI Governance Committee grants specific approval with safeguards:

#### 1. Organizing Campaign Intelligence (UC-13)
- **Risk:** Could enable surveillance or manipulation
- **Approval Required:** AI Governance Committee supermajority + ethics board review + member input
- **Safeguards:** Must demonstrate benefit outweighs risk, strict transparency, opt-in only

#### 2. Predictive Member Profiling
- **Risk:** Churn prediction could feel invasive
- **Approval Required:** Privacy impact assessment, opt-out option, fairness audit
- **Safeguards:** Used only for proactive member support, not punishment

#### 3. Automated Member Communications
- **Risk:** Impersonal, error-prone, could damage trust
- **Approval Required:** Human review, clear "AI-generated" labeling, opt-out available
- **Safeguards:** Used for routine updates only (deadlines, confirmations), not sensitive matters

#### 4. AI-Assisted Negotiation Strategy
- **Risk:** Could recommend suboptimal outcomes for efficiency
- **Approval Required:** Human negotiator oversight, member approval of AI involvement
- **Safeguards:** AI provides data/comparisons only, humans make all negotiation decisions

#### 5. Cross-Union Data Analysis
- **Risk:** Privacy violation if data shared without consent
- **Approval Required:** Explicit consent from all unions involved, anonymization
- **Safeguards:** Aggregate analysis only, no individual union/member identification

---

## 5. Ethical Decision-Making Framework

When ethical dilemmas arise, use this **four-step framework**:

### Step 1: Identify the Ethical Issue

**Questions to Ask:**
- Does this AI use affect member rights, privacy, fairness, or safety?
- Could this AI use be perceived as surveillance, manipulation, or discrimination?
- Are there competing interests (efficiency vs. privacy, accuracy vs. fairness)?
- Does this violate any absolute prohibition?

**Example Dilemma:**  
*"Should we use churn prediction AI to identify at-risk members?"*

**Ethical Issues:**
- Privacy: Profiling members without explicit consent
- Autonomy: Members unaware they're being predicted
- Fairness: Could predictions be biased by demographics?
- Benefit: Early intervention could save memberships

### Step 2: Apply Ethical Principles

Evaluate the AI use against our six principles:

| Principle | Question | Assessment |
|-----------|----------|------------|
| **Validity** | Is churn prediction accurate enough (>75%) to be useful? | ‚úÖ Models tested at 82% accuracy |
| **Accountability** | Who decides how to intervene with at-risk members? | ‚úÖ Human steward makes outreach decision |
| **Fairness** | Could predictions be biased by race, age, gender? | ‚ö†Ô∏è Requires fairness audit before deployment |
| **Safety** | Could this data be misused or breached? | ‚ö†Ô∏è Must ensure data security, no employer access |
| **Privacy** | Is member consent obtained? Are data rights respected? | ‚ùå Need opt-out option, transparency |
| **Explainability** | Can we explain to members why they were flagged? | ‚úÖ Risk factors can be communicated |

### Step 3: Consult Stakeholders

**Who to Consult:**
- Members (surveys, focus groups, town halls)
- Stewards (those who will use AI or be affected)
- Legal counsel (compliance, liability)
- AI Governance Committee (formal approval)
- External ethicists (complex cases)

**Churn Prediction Example Consultation:**
- Survey 100 members: "Would you want proactive outreach if union detected you might leave?"
  - Result: 78% said yes if anonymous and voluntary
- Steward focus group: "Is this helpful or creepy?"
  - Result: Helpful if framed as "early support," not surveillance
- Legal review: Privacy law compliance?
  - Result: Requires opt-out option and transparency

### Step 4: Make Decision with Safeguards

**Decision Matrix:**

| Outcome | Action |
|---------|--------|
| **Clear Ethical Approval** | Proceed with standard governance approval |
| **Ethical with Safeguards** | Implement with specific risk mitigations |
| **Ethically Uncertain** | Pilot test, gather feedback, reassess |
| **Ethically Problematic** | Do not proceed; revisit if circumstances change |

**Churn Prediction Decision:**  
‚úÖ **Approved with Safeguards:**
- Explicit opt-out option (default opt-in with clear disclosure)
- Fairness audit before deployment (quarterly ongoing)
- Used only for proactive member support (no punishment)
- 1-year data retention limit (then delete predictions)
- Transparency: Members told "We use AI to identify at-risk members for early support"
- Explainability: If member asks, explain risk factors (engagement drop, missed payments, complaints)

### Escalation Process

**Level 1:** AI/Product team identifies ethical issue ‚Üí Internal ethics discussion  
**Level 2:** Uncertain or medium-risk ‚Üí AI Governance Committee review  
**Level 3:** High-risk or controversial ‚Üí Committee supermajority + external ethicist  
**Level 4:** Fundamental policy question ‚Üí Union Executive Board approval  
**Level 5:** Major member rights issue ‚Üí Membership referendum

---

## 6. AI Ethics Committee Responsibilities

(See AI_GOVERNANCE_CHARTER.md for full committee structure)

### Ethical Oversight Duties

**Pre-Deployment Review:**
- All new AI use cases require ethics review
- High-risk AI requires supermajority approval
- Conditional prohibitions require special process

**Ongoing Monitoring:**
- Quarterly review of AI incidents (bias, errors, complaints)
- Annual ethics audit (external third party)
- Member feedback analysis (surveys, complaints)

**Policy Development:**
- Update AI Ethics Policy as needed (technology, regulations)
- Develop guidance for new AI use cases
- Resolve ethical dilemmas escalated by staff

### Ethics Training

**Committee Members:**
- AI ethics training within 30 days of joining (8 hours)
- Annual refresher (4 hours)
- Access to external ethics consultants

**AI/Data Science Team:**
- Comprehensive ethics training (16 hours initial, 8 hours annual)
- Case studies and scenario-based learning
- Certification in responsible AI practices

**All Staff/Stewards:**
- Basic AI ethics awareness (2 hours)
- Included in general AI training curriculum
- Annual reminders and updates

---

## 7. Member Rights & AI

### Right to Know

**Members have the right to know:**
- When AI is being used (clear disclosure)
- How AI affects them (predictions, recommendations)
- What data AI uses (transparency)
- Who benefits from AI (union, member, both)

**Implementation:**
- ü§ñ AI-Generated labels on all AI content
- "How AI Works" help pages for each feature
- Annual transparency report to membership
- Town halls or Q&A sessions

### Right to Opt-Out

**Members can opt out of:**
- Non-essential AI features (churn prediction, profiling)
- AI-generated communications (receive human-written only)
- AI training data contribution (anonymized data not used)

**Cannot Opt Out of:**
- Core services AI (claim predictions, precedent search) - but can request human-only alternative
- Aggregate analytics (anonymized, no individual impact)
- Security AI (fraud detection, threat monitoring)

**Implementation:**
- AI preferences page in member portal
- Opt-out honored within 7 days
- No penalty for opting out (same service quality)

### Right to Explanation

**Members can request explanation for:**
- Any AI prediction or recommendation affecting them
- Why they were flagged by AI (churn risk, etc.)
- How AI arrived at a conclusion

**Implementation:**
- "Why did AI predict this?" button on all predictions
- Natural language explanations (8th-grade reading level)
- Factor-based reasoning (top 3-5 factors shown)
- Human support available if explanation unclear

### Right to Human Review

**Members can request:**
- Human steward instead of AI recommendation
- Human override of AI decision
- Second opinion from non-AI process

**Implementation:**
- "Request Human Review" button always available
- Steward can override AI with documented reason
- No questions asked, no delay in service

### Right to Correction

**Members can:**
- Correct inaccurate data used by AI
- Request re-prediction with corrected data
- Challenge AI outcomes they believe are wrong

**Implementation:**
- Data correction process (7-day turnaround)
- Re-run AI prediction with corrected data (24 hours)
- Formal appeal process for disputed AI outcomes

### Right to Deletion

**Members can request:**
- Deletion of AI predictions about them
- Removal of data from AI training sets (prospective)
- "Right to be forgotten" (GDPR/PIPEDA)

**Implementation:**
- Deletion within 30 days (unless legal hold)
- Anonymization in historical training data (can't fully delete)
- Confirmation provided when deletion complete

---

## 8. Vendor & Third-Party AI Ethics

### Vendor Requirements

**All AI vendors (including Azure OpenAI) must:**

**1. Demonstrate Ethical AI Practices:**
- Published AI ethics policy
- Fairness and bias testing
- Transparency about training data sources
- Incident response capabilities

**2. Contractual Commitments:**
- Data privacy and security protections
- No use of Union Eyes data for vendor's own training (without consent)
- Compliance with Union Eyes ethical standards
- Right to audit vendor AI practices

**3. Prohibited Vendor Practices:**
- Training on Union Eyes member data without permission
- Sharing data with third parties
- Discriminatory AI models
- Lack of transparency about AI limitations

### Vendor Evaluation Process

**Pre-Contracting:**
1. Request vendor AI ethics policy and fairness audit results
2. Conduct vendor risk assessment (privacy, security, ethics)
3. Legal review of data processing agreement
4. AI Governance Committee approval for high-risk vendors

**Ongoing:**
- Annual vendor compliance audit
- Quarterly review of vendor AI updates (model changes, new features)
- Incident reporting requirements (vendor must notify us of AI issues)

### Azure OpenAI Specific Considerations

**Current Mitigations:**
- Data residency: US-based (East US region)
- No customer data used for OpenAI model training (per Microsoft agreement)
- Abuse monitoring by Microsoft (hate speech, illegal content)

**Ongoing Monitoring:**
- Azure OpenAI updates (new model versions, policy changes)
- Microsoft AI ethics practices (track developments)
- Alternative providers evaluated annually (reduce lock-in)

---

## 9. Ethical AI Culture

### Leadership Commitment

**Union Eyes Leadership pledges to:**
- Champion ethical AI in all decisions
- Allocate resources for fairness audits and ethics reviews
- Hold teams accountable for ethical AI practices
- Model transparent, values-driven AI use

**Specific Commitments:**
- 10% of AI budget reserved for ethics, fairness, privacy
- Executive compensation not tied to metrics that compromise ethics (no "launch AI fast" bonuses)
- Ethics concerns can be raised without retaliation

### Reporting Ethical Concerns

**Speak Up Culture:**
- All employees encouraged to raise AI ethics concerns
- No retaliation for good-faith ethics concerns
- Anonymous reporting option available

**Reporting Channels:**
1. **Manager or Team Lead:** For routine concerns
2. **AI Governance Committee:** [ai-ethics@unioneyes.org](mailto:ai-ethics@unioneyes.org)
3. **Data Privacy Officer:** For privacy-related concerns
4. **Ethics Hotline:** 1-800-XXX-XXXX (anonymous, third-party)
5. **Union Executive Board:** For serious violations

**Response Commitment:**
- Acknowledge report within 48 hours
- Investigate within 14 days
- Resolution and follow-up within 30 days
- Feedback to reporter (if not anonymous)

### Ethical AI Recognition

**Celebrate Ethical AI Practices:**
- "AI Ethics Champion" awards (annual)
- Recognize teams that prioritize fairness, transparency, member rights
- Share success stories (internal and external)

---

## 10. Policy Enforcement

### Violations & Consequences

**Minor Violations (Unintentional):**
- Example: Deploying AI feature without required fairness audit
- **Consequence:** Immediate rollback, conduct audit, retrain staff, document lessons learned

**Moderate Violations (Negligence):**
- Example: Ignoring bias detected in fairness audit
- **Consequence:** Formal warning, mandatory ethics retraining, probation for AI access

**Major Violations (Intentional):**
- Example: Developing AI for prohibited use (surveillance, manipulation)
- **Consequence:** Disciplinary action up to termination, legal action if applicable

**Vendor Violations:**
- Minor: Warning, corrective action plan
- Moderate: Contract suspension until resolved
- Major: Contract termination, legal action

### Enforcement Process

1. **Report:** Violation identified (audit, complaint, incident)
2. **Investigation:** AI Governance Committee + HR/Legal (7-14 days)
3. **Determination:** Violation severity, responsible parties
4. **Consequences:** Appropriate disciplinary action
5. **Remediation:** Fix AI system, prevent recurrence
6. **Documentation:** Incident report, lessons learned
7. **Transparency:** Public summary (anonymized) if major violation

---

## 11. Policy Review & Updates

### Annual Review

**Process:**
- AI Governance Committee reviews policy (December)
- Solicit feedback (staff, stewards, members, external experts)
- Propose updates based on:
  - Technology changes (new AI capabilities)
  - Regulatory changes (new laws, guidance)
  - Incident lessons learned
  - Industry best practices
- Union Executive Board approves major changes
- Communicate updates to all stakeholders

### Ad-Hoc Updates

**Triggers for immediate review:**
- Major AI incident (serious bias, privacy breach, harm)
- New regulation with AI implications (EU AI Act, state laws)
- Significant technology change (new AI model types)
- Member referendum or petition

### Version Control

- All policy versions archived
- Change log maintained (what changed, why, when)
- Previous version accessible (transparency)

---

## 12. Related Policies & Resources

**Related Documents:**
- [AI_PRINCIPLES.md](AI_PRINCIPLES.md) - Detailed implementation of six principles
- [AI_STRATEGY_ROADMAP.md](AI_STRATEGY_ROADMAP.md) - Overall AI strategy and vision
- [AI_GOVERNANCE_CHARTER.md](AI_GOVERNANCE_CHARTER.md) - Governance committee structure
- [AI_RISK_MANAGEMENT.md](AI_RISK_MANAGEMENT.md) - Risk framework and mitigation
- [FAIRNESS_AUDIT_FRAMEWORK.md](FAIRNESS_AUDIT_FRAMEWORK.md) - Bias detection procedures
- Union Eyes Privacy Policy (general)
- Union Eyes Data Security Policy (general)

**External Resources:**
- OECD AI Principles: https://oecd.ai/en/ai-principles
- EU AI Act: https://artificialintelligenceact.eu/
- IEEE Ethically Aligned Design: https://ethicsinaction.ieee.org/
- Montreal Declaration for Responsible AI: https://www.montrealdeclaration-responsibleai.com/

---

## 13. Conclusion & Commitment

Union Eyes is committed to deploying AI that serves workers, strengthens unions, and upholds labor values. This ethics policy ensures that innovation never comes at the expense of our core principles: solidarity, democracy, fairness, and member welfare.

**Our Pledge:**
- AI will augment, not replace, human judgment
- Member rights and privacy are non-negotiable
- Fairness and bias elimination are continuous commitments
- Transparency and accountability guide all AI decisions
- Democratic oversight ensures AI serves all members

**Ethics is everyone's responsibility.** From developers to stewards to members, we all play a role in ensuring AI at Union Eyes is ethical, fair, and worker-centered.

---

**Questions or Concerns?**  
Contact: [ai-ethics@unioneyes.org](mailto:ai-ethics@unioneyes.org)

**Report Ethics Violations:**  
Ethics Hotline: 1-800-XXX-XXXX (anonymous)  
Email: [ethics@unioneyes.org](mailto:ethics@unioneyes.org)

---

**Document Control:**
- **Version:** 1.0 (Draft)
- **Status:** Pending AI Governance Committee Approval (Q1 2026)
- **Approved By:** [Pending]
- **Next Review:** December 2026
- **Owner:** AI Governance Committee
- **Custodian:** Chief Technology Officer

---

*"Technology changes fast. Our values don't. Ethical AI means never compromising what unions stand for: worker power, dignity, fairness, and solidarity."*
